

## 文档：在 ESP32 (小智 AI 项目) 中集成 Edge Impulse C++ 库实现自定义唤醒词

**目标：** 通过集成 Edge Impulse 训练的唤醒词模型（以C++库形式导出），在 ESP32 上实现自定义唤醒词检测功能，并使其能与现有的“小智 AI 聊天机器人”项目协同工作。此方案独立于 ESP-SR 自带的 WakeNet 引擎。

**核心思路：** ESP32 独立运行 Edge Impulse 模型进行唤醒词识别，并将识别结果通知给小智 AI 的主应用逻辑。

------

### **阶段一：Edge Impulse 模型准备与导出**

1. **训练与优化 Edge Impulse 模型**：

   - 在 Edge Impulse Studio 中完成模型的训练、测试和验证。

   - 确保模型的准确率、召回率、延迟等性能指标满足项目需求。

   - 记录关键参数

     （后续 ESP32 代码配置需保持一致）：

     - 音频采样率 (Audio sample rate) - 例如 16000 Hz
     - 窗口大小 (Window size) - 单位 ms
     - 窗口增量 (Window increase) - 单位 ms
     - MFCC 特征数量 (Number of MFCC coefficients)
     - FFT 长度 (FFT length)

2. **部署模型为 C++ 库**：

   - 在 Edge Impulse 项目的 "Deployment" 页面选择 "C++ Library"。

   - 优化选项

     ：

     - 初次尝试建议选择 "Unoptimized (float32)" 以保证兼容性。
     - 若后续遇到性能或内存问题，可尝试 "Quantized (int8)"，但这可能需要重新调整和测试代码。

   - 点击 "Build" 按钮。

   - 下载生成的 `.zip` 文件。

------

### **阶段二：ESP-IDF 项目修改与库集成**

1. **准备 ESP-IDF 项目**：

   - 确保你的 ESP-IDF 开发环境（版本需符合项目要求，例如 >=v5.4.0）已正确安装并配置。本项目指的是 `xiaozhi-esp32`。

2. **集成 Edge Impulse C++ 库**：

   - **创建目录**：在 `xiaozhi-esp32/main/` 目录下（或作为独立组件在 `components/` 目录下）创建一个新文件夹，例如 `edge_impulse_wakeword`。

   - **复制文件**：解压步骤 2 中下载的 `.zip` 文件，将其中的 `edge-impulse-sdk`、`model-parameters`、`tflite-model` (或 `model-sources`，取决于导出选项) 等核心文件夹完整复制到新创建的 `edge_impulse_wakeword` 目录下。

   - 修改构建系统 (`main/CMakeLists.txt`)

     ：

     - 打开 `xiaozhi-esp32/main/CMakeLists.txt` 文件。

     - 在 

       ```
       set(SOURCES ...)
       ```

        声明或其后，添加 Edge Impulse 库的源文件。路径需根据实际解压结构调整：

       CMake

       ```c++
       # --- 添加 Edge Impulse 唤醒词相关文件 ---
       file(GLOB EI_WAKEWORD_SOURCES
            "${CMAKE_CURRENT_SOURCE_DIR}/edge_impulse_wakeword/edge-impulse-sdk/dsp/**/*.cpp"
            "${CMAKE_CURRENT_SOURCE_DIR}/edge_impulse_wakeword/edge-impulse-sdk/porting/espressif/*.cpp" # 适用于 ESP32
            # 根据你的模型类型选择以下之一：
            "${CMAKE_CURRENT_SOURCE_DIR}/edge_impulse_wakeword/tflite-model/*.cpp"  # 如果是 float32 模型
            # "${CMAKE_CURRENT_SOURCE_DIR}/edge_impulse_wakeword/model-sources/*.cpp" # 如果是 int8 模型
            # 注意：检查 Edge Impulse 导出的库中是否还有其他需要编译的 .c 或 .cpp 文件
       )
       list(APPEND SOURCES ${EI_WAKEWORD_SOURCES})
       
       # 添加 Edge Impulse 库的头文件搜索路径
       # 注意：此处的 INCLUDE_DIRS 变量在你的 CMakeLists.txt 中已有定义
       list(APPEND INCLUDE_DIRS
            "${CMAKE_CURRENT_SOURCE_DIR}/edge_impulse_wakeword/"
            "${CMAKE_CURRENT_SOURCE_DIR}/edge_impulse_wakeword/edge-impulse-sdk/"
            "${CMAKE_CURRENT_SOURCE_DIR}/edge_impulse_wakeword/model-parameters/"
            # 根据你的模型类型选择以下之一：
            "${CMAKE_CURRENT_SOURCE_DIR}/edge_impulse_wakeword/tflite-model/"
            # "${CMAKE_CURRENT_SOURCE_DIR}/edge_impulse_wakeword/model-sources/"
       )
       # --- Edge Impulse 相关文件添加结束 ---
       ```

     - **如果作为独立组件**：则在 `components/edge_impulse_wakeword/CMakeLists.txt` 中进行上述配置，并在 `main/idf_component.yml` 的 `dependencies` 中添加 `edge_impulse_wakeword: "*"` 或在 `main/CMakeLists.txt` 中使用 `idf_component_get_property` 后通过 `target_link_libraries` 链接。

------

### **阶段三：音频输入与处理**

1. **配置与获取音频输入**：

   - 你的项目 `xiaozhi-esp32` 已经包含音频处理逻辑，例如 `Application` 类中的 `AudioLoop()` 和 `ReadAudio()` 方法，以及具体的 `AudioCodec` 实现（如 `Es8311AudioCodec`）。
   - 你需要确保从 `AudioCodec` 获取的原始 PCM 音频数据是单声道、16位，并且采样率与 Edge Impulse 模型训练时所用的一致（例如 16000 Hz）。
   - 如果当前 `AudioCodec` 的 `input_sample_rate()` 与 EI 模型不一致，你需要在将数据传递给 EI 模型前进行重采样，或者调整 `AudioCodec` 的配置。`OpusResampler` 类 在项目中已有使用，可作参考。

2. **实现唤醒词检测逻辑 (`EiWakewordDetector` 类)**：

   - **创建文件**：在 `main/` 或 `main/edge_impulse_wakeword/` 目录下创建 `ei_wakeword_detector.h` 和 `ei_wakeword_detector.cc`。

   - 头文件 (`ei_wakeword_detector.h`)

     ：

     C++

     ```c++
     #ifndef EI_WAKEWORD_DETECTOR_H
     #define EI_WAKEWORD_DETECTOR_H
     
     #include <vector>
     #include <string>
     #include <functional>
     // 替换为 Edge Impulse 生成的实际头文件名
     #include "your_edge_impulse_project_name_inferencing.h"
     
     class EiWakewordDetector {
     public:
         EiWakewordDetector();
         // 回调函数，当检测到唤醒词时调用，参数为唤醒词标签
         void init(std::function<void(const char*)> on_wakeword_detected_callback);
         // 处理传入的音频数据段
         void process_audio_segment(const int16_t* audio_segment, size_t num_samples);
     
     private:
         std::function<void(const char*)> on_wakeword_detected_callback_;
         std::vector<int16_t> internal_audio_buffer_; // 用于实现滑动窗口
         size_t ei_window_size_samples_;       // EI模型需要的窗口大小（样本数）
         size_t ei_window_increase_samples_;   // EI模型窗口增量（样本数）
     };
     #endif // EI_WAKEWORD_DETECTOR_H
     ```

   - 实现文件 (`ei_wakeword_detector.cc`)

     ：

     C++

     ```c++
     #include "ei_wakeword_detector.h"
     #include "esp_log.h"
     
     static const char* TAG_EI = "EI_WakeWord";
     
     // 全局或静态成员，用于 Edge Impulse SDK 的回调
     static const int16_t* current_audio_slice_ptr = nullptr;
     
     int ei_raw_audio_get_data_cb(size_t offset, size_t length, float *out_ptr) {
         if (current_audio_slice_ptr == nullptr) return -1;
         numpy::int16_to_float(&current_audio_slice_ptr[offset], out_ptr, length);
         return 0;
     }
     
     EiWakewordDetector::EiWakewordDetector() :
         ei_window_size_samples_(EI_CLASSIFIER_DSP_INPUT_FRAME_SIZE),
         // 计算窗口增量对应的样本数
          // 这个计算方式需要确认，或者直接用 (EI_CLASSIFIER_INTERVAL_MS * YOUR_EI_SAMPLE_RATE / 1000)
         ei_window_increase_samples_(EI_CLASSIFIER_DSP_INPUT_FRAME_SIZE / (EI_CLASSIFIER_RAW_SAMPLE_COUNT / EI_CLASSIFIER_SLICES_PER_MODEL_WINDOW)) {
         internal_audio_buffer_.reserve(ei_window_size_samples_ * 2); // 为滑动窗口预留一些空间
     }
     
     void EiWakewordDetector::init(std::function<void(const char*)> callback) {
         on_wakeword_detected_callback_ = callback;
         // 如果 Edge Impulse SDK 有初始化函数，在此调用，例如：
         // if (run_classifier_init() != EI_IMPULSE_OK) {
         //     ESP_LOGE(TAG_EI, "Failed to initialize Edge Impulse classifier.");
         // }
         ESP_LOGI(TAG_EI, "Edge Impulse Wakeword Detector Initialized. Window size: %d samples, Window increase: %d samples",
                  (int)ei_window_size_samples_, (int)ei_window_increase_samples_);
     }
     
     void EiWakewordDetector::process_audio_segment(const int16_t* audio_segment, size_t num_samples) {
         // 将新的音频数据追加到内部缓冲区
         internal_audio_buffer_.insert(internal_audio_buffer_.end(), audio_segment, audio_segment + num_samples);
     
         // 当累积的数据足够一个窗口大小时，进行推理
         while (internal_audio_buffer_.size() >= ei_window_size_samples_) {
             current_audio_slice_ptr = internal_audio_buffer_.data(); // 为回调设置指针
     
             signal_t signal;
             signal.total_length = ei_window_size_samples_;
             signal.get_data = &ei_raw_audio_get_data_cb;
     
             ei_impulse_result_t result = {0};
             EI_IMPULSE_ERROR res = run_classifier(&signal, &result, false /* debug */);
     
             current_audio_slice_ptr = nullptr; // 清理指针
     
             if (res != EI_IMPULSE_OK) {
                 ESP_LOGE(TAG_EI, "EI run_classifier returned error: %d", res);
             } else {
                 // ESP_LOGI(TAG_EI, "DSP: %d ms, Classify: %d ms, Anomaly: %d ms",
                 //       result.timing.dsp, result.timing.classification, result.timing.anomaly);
                 for (size_t ix = 0; ix < EI_CLASSIFIER_LABEL_COUNT; ix++) {
                     // ESP_LOGI(TAG_EI, "  %s: %.5f", result.classification[ix].label, result.classification[ix].value);
                     // 替换 "your_custom_wakeword_label" 和阈值 0.80
                     if (strcmp(result.classification[ix].label, "your_custom_wakeword_label") == 0 && result.classification[ix].value > 0.80) {
                          ESP_LOGI(TAG_EI, "Custom Wakeword DETECTED: %s (%.2f)", result.classification[ix].label, result.classification[ix].value);
                          if (on_wakeword_detected_callback_) {
                              on_wakeword_detected_callback_(result.classification[ix].label);
                          }
                     }
                 }
             }
             // 实现滑动窗口：移除旧数据 (移除 Window Increase 大小的数据)
             internal_audio_buffer_.erase(internal_audio_buffer_.begin(), internal_audio_buffer_.begin() + ei_window_increase_samples_);
         }
     }
     ```

     - 替换

       ：

       - `"your_edge_impulse_project_name_inferencing.h"` 为 Edge Impulse 生成的实际 SDK 头文件名。
       - `"your_custom_wakeword_label"` 为你在 Edge Impulse 中为唤醒词设定的确切标签名。
       - 调整阈值 `0.80`。
       - 确认 `ei_window_increase_samples_` 的计算方式，它应该等于 Edge Impulse 中 "Window increase" 参数对应的样本数量。

     - **注意**：`ei_raw_audio_get_data_cb` 的实现依赖于 `current_audio_slice_ptr` 被正确设置。

3. **在 `Application` 类中集成 `EiWakewordDetector`**：

   - 修改 `main/application.h`

     ：

     C++

     ```c++
     // 在 class Application 声明中添加
     #include "ei_wakeword_detector.h" // 添加头文件
     
     private:
         // ... 其他成员 ...
         EiWakewordDetector ei_detector_;
     ```

   - 修改 `main/application.cc`

     ：

     - 构造函数 `Application::Application()`

       ：

       C++

       ```c++
       Application::Application() {
           // ... event_group_, background_task_ 初始化 ...
           // ... aec_mode_, audio_processor_, wake_word_ 初始化 ...
           // ... clock_timer 初始化 ...
       
           // 初始化 EiWakewordDetector
           ei_detector_.init([this](const char* wakeword_label) {
               ESP_LOGI(TAG, "[Application] Custom Wake Word '%s' detected by Edge Impulse!", wakeword_label);
               Schedule([this, label = std::string(wakeword_label)]() {
                   // 你可以根据需要决定这里的行为，是直接 ToggleChatState，
                   // 还是调用一个类似官方唤醒词的 WakeWordInvoke
                   if (device_state_ == kDeviceStateIdle) { //
                       ToggleChatState(); // 或者更具体的唤醒逻辑
                       // 如果需要，可以在协议层面发送一个唤醒事件
                       if (protocol_) { //
                           // protocol_->SendWakeWordDetected(label); // 取决于你的协议是否需要这个
                       }
                   } else if (device_state_ == kDeviceStateSpeaking) { //
                       AbortSpeaking(kAbortReasonWakeWordDetected); //
                   } else if (device_state_ == kDeviceStateActivating) { //
                        SetDeviceState(kDeviceStateIdle); //
                   }
               });
           });
       }
       ```

     - 修改 `Application::OnAudioInput()`

       ： 你需要从 

       ```c++
       codec_->InputData(data)c
       ```

        获取音频数据，然后传递给 

       ```c++
       ei_detector_
       ```

       。原函数中已有 

       ```c++
       wake_word_->Feed(data)
       ```

        和 

       ```c++
       audio_processor_->Feed(data)
       ```

       。你需要协调这三者。

       C++

       ```c++
       void Application::OnAudioInput() {
           std::vector<int16_t> audio_data_segment;
           // 确定每次读取的样本数量，应与 ei_detector_ 的窗口增量协调
           // 例如，如果 EI 的 Window increase 是 100ms，采样率16kHz，则 samples_for_ei_segment = 1600
           // 确保 audio_data_segment 填充了正确数量的、符合 EI 模型采样率的样本
           int samples_to_read = /* 根据你的 EI 配置计算 */; // 例如 160 for 10ms at 16kHz for smaller chunks
       
           if (ReadAudio(audio_data_segment, 16000 /* 确保是EI模型期望的采样率 */, samples_to_read)) { //
               // 喂给官方唤醒词引擎（如果启用且正在运行）
               if (wake_word_ && wake_word_->IsDetectionRunning()) { //
                   // 注意：官方 wake_word_ 可能需要不同的数据块大小 (GetFeedSize())
                   // 你可能需要调整或分别处理提供给官方引擎的数据。
                   // 示例：
                   // if (audio_data_segment.size() >= wake_word_->GetFeedSize()) {
                   //     wake_word_->Feed(std::vector<int16_t>(audio_data_segment.begin(), audio_data_segment.begin() + wake_word_->GetFeedSize()));
                   // }
               }
       
               // 喂给 Edge Impulse 唤醒词检测器
               ei_detector_.process_audio_segment(audio_data_segment.data(), audio_data_segment.size());
       
               // 喂给 AFE 音频处理器（如果启用且正在运行）
               if (audio_processor_ && audio_processor_->IsRunning()) { //
                   // audio_processor_->Feed(audio_data_segment); // 同上，注意数据块大小
               }
           } else {
               vTaskDelay(pdMS_TO_TICKS(10)); 
           }
            // 根据需要调整 OnAudioInput 的调用频率，例如匹配 EI 的 window increase
            // vTaskDelay(pdMS_TO_TICKS(EI_CLASSIFIER_INTERVAL_MS > 0 ? EI_CLASSIFIER_INTERVAL_MS / 2 : 50));
       }
       ```

       滑动窗口与数据供给的重要提示

       ：

       - 确保 `ReadAudio()` 函数读取的音频数据采样率与 Edge Impulse 模型训练时使用的采样率一致。
       - `EiWakewordDetector::process_audio_segment()` 被设计为接收连续的音频片段。`Application::OnAudioInput()` 应该以一个合适的固定间隔（例如，与 Edge Impulse 模型的 "Window increase" 参数对应的时间，或者更小）调用，并将新获取的音频数据片段传递给 `process_audio_segment`。`EiWakewordDetector` 内部的 `internal_audio_buffer_` 会负责将这些片段拼接起来，并按需提取完整的窗口数据进行推理。

------

### **阶段四：编译、烧录与调试**

1. **分区表检查**：
   - Edge Impulse 模型会增加固件大小。检查项目中的 `partitions.csv` 文件（如 `partitions_8M.csv` 或 `partitions_4M.csv`），确保应用分区（如 `ota_0`、`factory`）有足够的空间。如果项目使用了 `model` 分区，并且你希望将 EI 模型数据放在那里（这需要更高级的加载机制，通常不直接这样做），则另行考虑。目前方案是将模型编译进应用固件。
2. **编译项目**：
   - `idf.py build`
3. **烧录固件**：
   - `idf.py -p /你的/ESP32串口 flash` (替换为你的实际串口)
4. **监控和调试**：
   - `idf.py monitor`
   - 观察日志输出，特别是 `TAG_EI` 和 `Application` 中添加的日志。
   - 验证自定义唤醒词能否触发 `on_wakeword_detected_callback_` 及后续的应用逻辑。
   - 仔细调试音频采样率、滑动窗口的实现是否正确。
   - 根据实际效果，调整 `EiWakewordDetector::process_audio_segment` 中唤醒词识别的阈值。
   - 检查任务栈大小，特别是 `AudioLoop` 任务。Edge Impulse 的推理过程可能会消耗较多栈。可以使用 `uxTaskGetStackHighWaterMark()` 进行检查。

------

**关键注意事项**：

- **资源消耗**：Edge Impulse 模型（尤其是神经网络）的运行会消耗 CPU 和 RAM。你需要确保 ESP32-S3 有足够的处理能力和内存。考虑使用 ESP32-S3 的 PSRAM (通过 `menuconfig` 配置)。
- **任务优先级**：音频输入和唤醒词检测任务需要较高的优先级以保证实时性。`Application::AudioLoop` 任务优先级已在项目中设置。
- **音频数据流同步**：确保 Edge Impulse 的 `process_audio_segment` 能够得到正确格式和时序的音频。
- **调试**：充分利用 `ESP_LOGI` 和 `ESP_LOGE` 进行调试。可以打印音频缓冲区的状态、推理结果的概率值等。

